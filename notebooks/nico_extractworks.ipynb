{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d472e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from slugify import slugify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102d5115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pyalex\n",
    "def get_git_user():\n",
    "    res = subprocess.run([\"git\", \"config\", \"user.email\"], stdout=subprocess.PIPE)\n",
    "    return res.stdout.strip().decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31c7db",
   "metadata": {},
   "source": [
    "## 1. Load list of relevant journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6c933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Journal name</th>\n",
       "      <th>JCR Abbreviation</th>\n",
       "      <th>ISSN</th>\n",
       "      <th>eISSN</th>\n",
       "      <th>Category</th>\n",
       "      <th>Total Citations</th>\n",
       "      <th>2022 JIF</th>\n",
       "      <th>JIF Quartile</th>\n",
       "      <th>2022 JCI</th>\n",
       "      <th>% of OA Gold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANNALS OF TOURISM RESEARCH</td>\n",
       "      <td>ANN TOURISM RES</td>\n",
       "      <td>0160-7383</td>\n",
       "      <td>1873-7722</td>\n",
       "      <td>SOCIOLOGY - SSCI</td>\n",
       "      <td>19,874</td>\n",
       "      <td>13.2</td>\n",
       "      <td>Q1</td>\n",
       "      <td>3.52</td>\n",
       "      <td>17.21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual Review of Sociology</td>\n",
       "      <td>ANNU REV SOCIOL</td>\n",
       "      <td>0360-0572</td>\n",
       "      <td>1545-2115</td>\n",
       "      <td>SOCIOLOGY - SSCI</td>\n",
       "      <td>15,214</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Q1</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMERICAN SOCIOLOGICAL REVIEW</td>\n",
       "      <td>AM SOCIOL REV</td>\n",
       "      <td>0003-1224</td>\n",
       "      <td>1939-8271</td>\n",
       "      <td>SOCIOLOGY - SSCI</td>\n",
       "      <td>25,619</td>\n",
       "      <td>9.1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>4.98</td>\n",
       "      <td>13.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUROPEAN SOCIETIES</td>\n",
       "      <td>EUR SOC</td>\n",
       "      <td>1461-6696</td>\n",
       "      <td>1469-8307</td>\n",
       "      <td>SOCIOLOGY - SSCI</td>\n",
       "      <td>2,158</td>\n",
       "      <td>8.1</td>\n",
       "      <td>Q1</td>\n",
       "      <td>2.54</td>\n",
       "      <td>34.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOCIOLOGICAL METHODS &amp; RESEARCH</td>\n",
       "      <td>SOCIOL METHOD RES</td>\n",
       "      <td>0049-1241</td>\n",
       "      <td>1552-8294</td>\n",
       "      <td>SOCIOLOGY - SSCI</td>\n",
       "      <td>8,840</td>\n",
       "      <td>6.3</td>\n",
       "      <td>Q1</td>\n",
       "      <td>3.18</td>\n",
       "      <td>15.87%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Journal name   JCR Abbreviation       ISSN      eISSN  \\\n",
       "0       ANNALS OF TOURISM RESEARCH    ANN TOURISM RES  0160-7383  1873-7722   \n",
       "1       Annual Review of Sociology    ANNU REV SOCIOL  0360-0572  1545-2115   \n",
       "2     AMERICAN SOCIOLOGICAL REVIEW      AM SOCIOL REV  0003-1224  1939-8271   \n",
       "3               EUROPEAN SOCIETIES            EUR SOC  1461-6696  1469-8307   \n",
       "4  SOCIOLOGICAL METHODS & RESEARCH  SOCIOL METHOD RES  0049-1241  1552-8294   \n",
       "\n",
       "           Category Total Citations 2022 JIF JIF Quartile  2022 JCI  \\\n",
       "0  SOCIOLOGY - SSCI          19,874     13.2           Q1      3.52   \n",
       "1  SOCIOLOGY - SSCI          15,214     10.5           Q1      4.30   \n",
       "2  SOCIOLOGY - SSCI          25,619      9.1           Q1      4.98   \n",
       "3  SOCIOLOGY - SSCI           2,158      8.1           Q1      2.54   \n",
       "4  SOCIOLOGY - SSCI           8,840      6.3           Q1      3.18   \n",
       "\n",
       "  % of OA Gold  \n",
       "0       17.21%  \n",
       "1        1.15%  \n",
       "2       13.91%  \n",
       "3       34.97%  \n",
       "4       15.87%  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journals_list = pd.read_csv(\"../reviewerSelection-data/JCR_JournalResults_Sociology.csv\")\n",
    "journals_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ed762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"try_journals = journals_list.loc[[1, 3]]\\ntry_journals_issn = try_journals.filter(items=['ISSN'])\\ntry_journals_issn\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''try_journals = journals_list.loc[[1, 3]]\n",
    "try_journals_issn = try_journals.filter(items=['ISSN'])\n",
    "try_journals_issn'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8263a0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total_list = []\\nfor issn in try_journals_issn[\\'ISSN\\']:    \\n    curr_res_list = []\\n    cursor = \\'*\\'\\n    select = \\'id,authorships,publication_year,display_name,primary_location,cited_by_count,language\\'\\n    while cursor != None:\\n        filter = f\\'primary_location.source.issn:{issn}\\'\\n        params = {\\n            \\'filter\\': filter,\\n            \\'per_page\\': 200,\\n            \\'cursor\\': cursor,\\n            \\'select\\': select\\n        }\\n        res = requests.get(\"https://api.openalex.org/works\", params=params).json()\\n        for work in range(len(res[\\'results\\'])): \\n            curr_res = res[\\'results\\'][work]\\n            curr_res_list.append(curr_res)\\n        cursor = res[\\'meta\\'].get(\\'next_cursor\\', None)\\n        print(res)\\n        print(cursor)\\n        print(len(curr_res_list))\\n    \\n    total_list.append(curr_res_list)\\n    print((len(total_list)))'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''total_list = []\n",
    "for issn in try_journals_issn['ISSN']:    \n",
    "    curr_res_list = []\n",
    "    cursor = '*'\n",
    "    select = 'id,authorships,publication_year,display_name,primary_location,cited_by_count,language'\n",
    "    while cursor != None:\n",
    "        filter = f'primary_location.source.issn:{issn}'\n",
    "        params = {\n",
    "            'filter': filter,\n",
    "            'per_page': 200,\n",
    "            'cursor': cursor,\n",
    "            'select': select\n",
    "        }\n",
    "        res = requests.get(\"https://api.openalex.org/works\", params=params).json()\n",
    "        for work in range(len(res['results'])): \n",
    "            curr_res = res['results'][work]\n",
    "            curr_res_list.append(curr_res)\n",
    "        cursor = res['meta'].get('next_cursor', None)\n",
    "        print(res)\n",
    "        print(cursor)\n",
    "        print(len(curr_res_list))\n",
    "    \n",
    "    total_list.append(curr_res_list)\n",
    "    print((len(total_list)))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47f8e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end_list = []\\nfor sec_list in total_list:\\n    for third_list in sec_list:\\n        end_list.append(third_list)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''end_list = []\n",
    "for sec_list in total_list:\n",
    "    for third_list in sec_list:\n",
    "        end_list.append(third_list)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a345b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"all_ids = []\\nall_authors = []\\nall_titles = []\\nall_pub_years = []\\nall_journal_names = []\\nall_journal_issnls = []\\nall_cited_counts = []\\nall_languages = []\\n\\n\\nfor work in end_list:\\n    # IDs\\n    id = work['id']\\n    # Title\\n    title = work['display_name']\\n    # Author list\\n    authors = []\\n    for author in work['authorships']:\\n        authors.append(author['author']['display_name'])\\n    # Publication year\\n    pub_year = work['publication_year']\\n    # Journal Name\\n    journal_name = work['primary_location']['source']['display_name']\\n    # Journal Issn_l\\n    journal_issnl = work['primary_location']['source']['issn_l']\\n    # Cited by count\\n    cited_count = work['cited_by_count']\\n    # Language\\n    language = work['language']\\n    \\n    # Append to each list\\n    all_ids.append(id)\\n    all_titles.append(title)\\n    all_authors.append(authors)\\n    all_pub_years.append(pub_year)\\n    all_journal_names.append(journal_name)\\n    all_journal_issnls.append(journal_issnl)\\n    all_cited_counts.append(cited_count)\\n    all_languages.append(language)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''all_ids = []\n",
    "all_authors = []\n",
    "all_titles = []\n",
    "all_pub_years = []\n",
    "all_journal_names = []\n",
    "all_journal_issnls = []\n",
    "all_cited_counts = []\n",
    "all_languages = []\n",
    "\n",
    "\n",
    "for work in end_list:\n",
    "    # IDs\n",
    "    id = work['id']\n",
    "    # Title\n",
    "    title = work['display_name']\n",
    "    # Author list\n",
    "    authors = []\n",
    "    for author in work['authorships']:\n",
    "        authors.append(author['author']['display_name'])\n",
    "    # Publication year\n",
    "    pub_year = work['publication_year']\n",
    "    # Journal Name\n",
    "    journal_name = work['primary_location']['source']['display_name']\n",
    "    # Journal Issn_l\n",
    "    journal_issnl = work['primary_location']['source']['issn_l']\n",
    "    # Cited by count\n",
    "    cited_count = work['cited_by_count']\n",
    "    # Language\n",
    "    language = work['language']\n",
    "    \n",
    "    # Append to each list\n",
    "    all_ids.append(id)\n",
    "    all_titles.append(title)\n",
    "    all_authors.append(authors)\n",
    "    all_pub_years.append(pub_year)\n",
    "    all_journal_names.append(journal_name)\n",
    "    all_journal_issnls.append(journal_issnl)\n",
    "    all_cited_counts.append(cited_count)\n",
    "    all_languages.append(language)'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63f9cae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df = pd.DataFrame({\\n    'id': all_ids,\\n    'authors': all_authors,\\n    'title': all_titles,\\n    'publication_year': all_pub_years,\\n    'journal_name': all_journal_names,\\n    'journal_issnl': all_journal_issnls,\\n    'cited_by_count': all_cited_counts,\\n    'language': all_languages\\n})\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = pd.DataFrame({\n",
    "    'id': all_ids,\n",
    "    'authors': all_authors,\n",
    "    'title': all_titles,\n",
    "    'publication_year': all_pub_years,\n",
    "    'journal_name': all_journal_names,\n",
    "    'journal_issnl': all_journal_issnls,\n",
    "    'cited_by_count': all_cited_counts,\n",
    "    'language': all_languages\n",
    "})'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2419598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['authors_first_lastname'] = df['authors'].apply(lambda x: x[0].lower().replace('.', '').split()[-1] if len(x)>0 else '')\\ndf['authors_first_lastname']\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df['authors_first_lastname'] = df['authors'].apply(lambda x: x[0].lower().replace('.', '').split()[-1] if len(x)>0 else '')\n",
    "df['authors_first_lastname']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96467504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['title_slugified'] = df['title'].apply(lambda x: slugify(x) if type(x)==str else '')\\ndf['title_slugified']\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df['title_slugified'] = df['title'].apply(lambda x: slugify(x) if type(x)==str else '')\n",
    "df['title_slugified']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6835aa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df['concat_name_title'] = df['authors_first_lastname'] + '-' + df['title_slugified']\\ndf['concat_name_title']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df['concat_name_title'] = df['authors_first_lastname'] + '-' + df['title_slugified']\n",
    "df['concat_name_title']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fdb4bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"df.to_csv('two_journals.csv')\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df.to_csv('two_journals.csv')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832215ad",
   "metadata": {},
   "source": [
    "## Extract works from OpenAlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b533748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_works_relevant(list_relevant):\n",
    "    '''Returns dataframe of all works from OpenAlex from all journals in list_relevant.'''\n",
    "    user_mail = get_git_user()\n",
    "    current_date = '2023-08-29' #year-month-day\n",
    "    year_limit = 2023 - 30  #year - 30\n",
    "    date_limit = f'{year_limit}' + current_date[-6:]\n",
    "\n",
    "    total_list = []\n",
    "    for issn in list_relevant['ISSN']:\n",
    "        \n",
    "        curr_res_list = []\n",
    "        cursor = '*'\n",
    "        select = 'id,authorships,publication_year,display_name,primary_location,cited_by_count,language'\n",
    "        \n",
    "        while cursor != None:\n",
    "            filters = f'primary_location.source.issn:{issn},from_publication_date:{date_limit},to_publication_date:{current_date}'\n",
    "            params = {\n",
    "                'filter': filters,\n",
    "                'per_page': 200,\n",
    "                'cursor': cursor,\n",
    "                'select': select,\n",
    "                'mailto': user_mail\n",
    "            }\n",
    "            res = requests.get(\"https://api.openalex.org/works\", params=params).json()\n",
    "            for work in range(len(res['results'])): \n",
    "                curr_res = res['results'][work]\n",
    "                curr_res_list.append(curr_res)\n",
    "            cursor = res['meta'].get('next_cursor', None)\n",
    "            print(len(curr_res_list))\n",
    "\n",
    "        total_list.append(curr_res_list)\n",
    "        print(len(total_list))\n",
    "    \n",
    "    return total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54fe7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(total_list):\n",
    "    '''Create a dataframe out of the works in pages in a list. Returns df.''' \n",
    "    \n",
    "    #Create list of works\n",
    "    end_list = []\n",
    "    for sec_list in total_list:\n",
    "        for third_list in sec_list:\n",
    "            end_list.append(third_list)\n",
    "    \n",
    "    all_ids = []\n",
    "    all_titles = []\n",
    "    all_authors = []\n",
    "    all_pub_years = []\n",
    "    all_journal_names = []\n",
    "    all_journal_issnls = []\n",
    "    all_cited_counts = []\n",
    "    all_languages = []\n",
    "\n",
    "\n",
    "    for work in end_list:\n",
    "        # IDs\n",
    "        id = work['id']\n",
    "        # Title\n",
    "        title = work['display_name']\n",
    "        # Author list\n",
    "        authors = []\n",
    "        for author in work['authorships']:\n",
    "            authors.append(author['author'].get('display_name', ''))\n",
    "        # Publication year\n",
    "        pub_year = work['publication_year']\n",
    "        # Journal Name\n",
    "        journal_name = work['primary_location']['source']['display_name']\n",
    "        # Journal Issn_l\n",
    "        journal_issnl = work['primary_location']['source']['issn_l']\n",
    "        # Cited by count\n",
    "        cited_count = work['cited_by_count']\n",
    "        # Language\n",
    "        language = work['language']\n",
    "        \n",
    "        # Append to each list\n",
    "        all_ids.append(id)\n",
    "        all_titles.append(title)\n",
    "        all_authors.append(authors)\n",
    "        all_pub_years.append(pub_year)\n",
    "        all_journal_names.append(journal_name)\n",
    "        all_journal_issnls.append(journal_issnl)\n",
    "        all_cited_counts.append(cited_count)\n",
    "        all_languages.append(language)\n",
    "        \n",
    "    #Turn into df\n",
    "    df = pd.DataFrame({\n",
    "    'id': all_ids,\n",
    "    'authors': all_authors,\n",
    "    'title': all_titles,\n",
    "    'publication_year': all_pub_years,\n",
    "    'journal_name': all_journal_names,\n",
    "    'journal_issnl': all_journal_issnls,\n",
    "    'cited_by_count': all_cited_counts,\n",
    "    'language': all_languages\n",
    "    })\n",
    "       \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bcbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_author_title(df):\n",
    "    '''Add a column with the first authors last name and title of the work to the dataframe. Returns dataframe.'''\n",
    "    df['authors_first_lastname'] = df['authors'].apply(lambda x: x[0].lower().replace('.', '').split()[-1] if len(x)>0 else '')\n",
    "    df['title_slugified'] = df['title'].apply(lambda x: slugify(x) if type(x)==str else '')\n",
    "    df['concat_name_title'] = df['authors_first_lastname'] + '-' + df['title_slugified']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14bcc274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m all_journals \u001b[39m=\u001b[39m journals_list\u001b[39m.\u001b[39mfilter(items\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mISSN\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m df_step1 \u001b[39m=\u001b[39m extract_works_relevant(all_journals)\n\u001b[1;32m      3\u001b[0m df_step2 \u001b[39m=\u001b[39m create_df(df_step1)\n\u001b[1;32m      4\u001b[0m end_df \u001b[39m=\u001b[39m concat_author_title(df_step2)\n",
      "Cell \u001b[0;32mIn[13], line 24\u001b[0m, in \u001b[0;36mextract_works_relevant\u001b[0;34m(list_relevant)\u001b[0m\n\u001b[1;32m     16\u001b[0m filters \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprimary_location.source.issn:\u001b[39m\u001b[39m{\u001b[39;00missn\u001b[39m}\u001b[39;00m\u001b[39m,from_publication_date:\u001b[39m\u001b[39m{\u001b[39;00mdate_limit\u001b[39m}\u001b[39;00m\u001b[39m,to_publication_date:\u001b[39m\u001b[39m{\u001b[39;00mcurrent_date\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     17\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfilter\u001b[39m\u001b[39m'\u001b[39m: filters,\n\u001b[1;32m     19\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mper_page\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m200\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmailto\u001b[39m\u001b[39m'\u001b[39m: user_mail\n\u001b[1;32m     23\u001b[0m }\n\u001b[0;32m---> 24\u001b[0m res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://api.openalex.org/works\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams)\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m work \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m])): \n\u001b[1;32m     26\u001b[0m     curr_res \u001b[39m=\u001b[39m res[\u001b[39m'\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m'\u001b[39m][work]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     r\u001b[39m.\u001b[39;49mcontent\n\u001b[1;32m    749\u001b[0m \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content \u001b[39m=\u001b[39m \u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_content(CONTENT_CHUNK_SIZE)) \u001b[39mor\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_content_consumed \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[39m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/response.py:940\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp) \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    942\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    943\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m amt:\n\u001b[1;32m    877\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decoded_buffer\u001b[39m.\u001b[39mget(amt)\n\u001b[0;32m--> 879\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_read(amt)\n\u001b[1;32m    881\u001b[0m flush_decoder \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    882\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/response.py:814\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    811\u001b[0m fp_closed \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp, \u001b[39m\"\u001b[39m\u001b[39mclosed\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    813\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 814\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp_read(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    815\u001b[0m     \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data:\n\u001b[1;32m    816\u001b[0m         \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[39m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/response.py:799\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[39mreturn\u001b[39;00m buffer\u001b[39m.\u001b[39mgetvalue()\n\u001b[1;32m    797\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    798\u001b[0m     \u001b[39m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mread()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_journals = journals_list.filter(items=['ISSN'])\n",
    "df_step1 = extract_works_relevant(all_journals)\n",
    "df_step2 = create_df(df_step1)\n",
    "end_df = concat_author_title(df_step2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d527c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_works_sociology.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
